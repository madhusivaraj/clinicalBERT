{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731eab2f",
   "metadata": {},
   "source": [
    "# Ablation 2: Migrating from pytorch-pretrained-bert to Transformers\n",
    "\n",
    "In the original implementation of ClinicalBERT, Huang et al. rely on pytorch-pretrained-bert, the PyTorch version of Google AI BERT model with script to load Google pre-trained models. See https://pypi.org/project/pytorch-pretrained-bert/ for more information.\n",
    "\n",
    "We decided to run a secondary ablation - migrate from the pytorch-pretrained-bert library to using the more sophisticated Transformers library - and see if there would be any performance improvements in terms of accuracy or computational complexity (ie. runtime).\n",
    "\n",
    "Transformers is a library of over 32 state-of-the-art pre-trained models for natural language processing. We updated our ClinicalBERT model with Transformers, reimplementing the forward method to always output a tuple with encoded layers and pooled output. The two optimizers---BertAdam and OpenAIAdam---have been replaced by a single AdamW optimizer, so we replaced BertAdam with AdamW, following the same decay schedule.\n",
    "\n",
    "We ran 3 independent trials, with a batch size of 3, learning rate of 0.00005, hidden size of 768, and dropout rate of 0.1. Table 7 reveals that while our reproduced ClinicalBERT had a combined runtime of 9h26m for both experiment, the ablations with adding Transformers resulted in a 84% decrease to 1h28m. Table 1 and 2 also reveal the AUROC and AUPRC values of reproduced and modified ClinicalBERT models, on discharge and early clinical notes, are within a 1% margin of each other. Given the lower compute time and higher AUROC and AUPRC for both tasks, these findings reinforce Huang et al.’s speculation and our hypothesis that finetuning may yield better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dcecde",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925579c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from tqdm import tqdm, trange\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from transformers import BertTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from modeling_readmission import BertForSequenceClassification\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, auc, confusion_matrix, classification_report\n",
    "from funcsigs import signature\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f7167d",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ae41f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm = pd.read_csv('./physionet.org/files/mimiciii/1.4/ADMISSIONS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f74b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/lt7qchz54wlcnz8s602v0kn80000gn/T/ipykernel_8941/2760791028.py:1: DtypeWarning: Columns (4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_notes=pd.read_csv('./physionet.org/files/mimiciii/1.4/NOTEEVENTS.csv')\n"
     ]
    }
   ],
   "source": [
    "df_notes=pd.read_csv('./physionet.org/files/mimiciii/1.4/NOTEEVENTS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e63339a",
   "metadata": {},
   "source": [
    "### Admissions.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ca729c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm.ADMITTIME = pd.to_datetime(df_adm.ADMITTIME, format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df_adm.DISCHTIME = pd.to_datetime(df_adm.DISCHTIME, format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df_adm.DEATHTIME = pd.to_datetime(df_adm.DEATHTIME, format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "df_adm = df_adm.sort_values(['SUBJECT_ID', 'ADMITTIME'])\n",
    "df_adm = df_adm.reset_index(drop=True)\n",
    "df_adm['NEXT_ADMITTIME'] = df_adm.groupby('SUBJECT_ID').ADMITTIME.shift(-1)\n",
    "df_adm['NEXT_ADMISSION_TYPE'] = df_adm.groupby('SUBJECT_ID').ADMISSION_TYPE.shift(-1)\n",
    "rows = df_adm.NEXT_ADMISSION_TYPE == 'ELECTIVE'\n",
    "df_adm.loc[rows,'NEXT_ADMITTIME'] = pd.NaT\n",
    "df_adm.loc[rows,'NEXT_ADMISSION_TYPE'] = np.NaN\n",
    "df_adm = df_adm.sort_values(['SUBJECT_ID','ADMITTIME'])\n",
    "df_adm[['NEXT_ADMITTIME','NEXT_ADMISSION_TYPE']] = df_adm.groupby(['SUBJECT_ID'])[['NEXT_ADMITTIME','NEXT_ADMISSION_TYPE']].fillna(method = 'bfill')\n",
    "df_adm['DAYS_NEXT_ADMIT'] = (df_adm.NEXT_ADMITTIME - df_adm.DISCHTIME).dt.total_seconds()/(24*60*60)\n",
    "df_adm = df_adm.loc[df_adm.ADMISSION_TYPE != 'NEWBORN']\n",
    "df_adm = df_adm.loc[df_adm.DEATHTIME.isnull()]\n",
    "df_adm['OUTPUT_LABEL'] = (df_adm.DAYS_NEXT_ADMIT < 30).astype('int')\n",
    "df_adm['DURATION'] = (df_adm['DISCHTIME']-df_adm['ADMITTIME']).dt.total_seconds()/(24*60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f428f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>DEATHTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>ADMISSION_LOCATION</th>\n",
       "      <th>DISCHARGE_LOCATION</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>...</th>\n",
       "      <th>EDREGTIME</th>\n",
       "      <th>EDOUTTIME</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>HOSPITAL_EXPIRE_FLAG</th>\n",
       "      <th>HAS_CHARTEVENTS_DATA</th>\n",
       "      <th>NEXT_ADMITTIME</th>\n",
       "      <th>NEXT_ADMISSION_TYPE</th>\n",
       "      <th>DAYS_NEXT_ADMIT</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "      <th>DURATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>2101-10-20 19:08:00</td>\n",
       "      <td>2101-10-31 13:58:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>SNF</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>2101-10-20 17:09:00</td>\n",
       "      <td>2101-10-20 19:24:00</td>\n",
       "      <td>HYPOTENSION</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10.784722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>185777</td>\n",
       "      <td>2191-03-16 00:28:00</td>\n",
       "      <td>2191-03-23 18:41:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>HOME WITH HOME IV PROVIDR</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>2191-03-15 13:10:00</td>\n",
       "      <td>2191-03-16 01:10:00</td>\n",
       "      <td>FEVER,DEHYDRATION,FAILURE TO THRIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.759028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>107064</td>\n",
       "      <td>2175-05-30 07:15:00</td>\n",
       "      <td>2175-06-15 16:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CHRONIC RENAL FAILURE/SDA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>16.364583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>194540</td>\n",
       "      <td>2178-04-16 06:18:00</td>\n",
       "      <td>2178-05-11 19:00:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>2178-04-15 20:46:00</td>\n",
       "      <td>2178-04-16 06:53:00</td>\n",
       "      <td>BRAIN MASS</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>25.529167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>143045</td>\n",
       "      <td>2167-01-08 18:43:00</td>\n",
       "      <td>2167-01-15 15:15:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Medicaid</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CORONARY ARTERY DISEASE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6.855556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58971</th>\n",
       "      <td>58972</td>\n",
       "      <td>99985</td>\n",
       "      <td>176670</td>\n",
       "      <td>2181-01-27 02:47:00</td>\n",
       "      <td>2181-02-12 17:05:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>2181-01-26 23:35:00</td>\n",
       "      <td>2181-01-27 04:18:00</td>\n",
       "      <td>FEVER</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>16.595833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58972</th>\n",
       "      <td>58973</td>\n",
       "      <td>99991</td>\n",
       "      <td>151118</td>\n",
       "      <td>2184-12-24 08:30:00</td>\n",
       "      <td>2185-01-05 12:15:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Private</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DIVERTICULITIS/SDA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12.156250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58973</th>\n",
       "      <td>58974</td>\n",
       "      <td>99992</td>\n",
       "      <td>197084</td>\n",
       "      <td>2144-07-25 18:03:00</td>\n",
       "      <td>2144-07-28 17:56:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>CLINIC REFERRAL/PREMATURE</td>\n",
       "      <td>SNF</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>2144-07-25 13:40:00</td>\n",
       "      <td>2144-07-25 18:50:00</td>\n",
       "      <td>RETROPERITONEAL HEMORRHAGE</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2.995139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58974</th>\n",
       "      <td>58975</td>\n",
       "      <td>99995</td>\n",
       "      <td>137810</td>\n",
       "      <td>2147-02-08 08:00:00</td>\n",
       "      <td>2147-02-11 13:15:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABDOMINAL AORTIC ANEURYSM/SDA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58975</th>\n",
       "      <td>58976</td>\n",
       "      <td>99999</td>\n",
       "      <td>113369</td>\n",
       "      <td>2117-12-30 07:15:00</td>\n",
       "      <td>2118-01-04 16:30:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>PHYS REFERRAL/NORMAL DELI</td>\n",
       "      <td>SNF</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPONDYLOLISTHESIS/SDA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.385417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45321 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ROW_ID  SUBJECT_ID  HADM_ID           ADMITTIME           DISCHTIME  \\\n",
       "1           2           3   145834 2101-10-20 19:08:00 2101-10-31 13:58:00   \n",
       "2           3           4   185777 2191-03-16 00:28:00 2191-03-23 18:41:00   \n",
       "4           5           6   107064 2175-05-30 07:15:00 2175-06-15 16:00:00   \n",
       "9          10          11   194540 2178-04-16 06:18:00 2178-05-11 19:00:00   \n",
       "11         12          13   143045 2167-01-08 18:43:00 2167-01-15 15:15:00   \n",
       "...       ...         ...      ...                 ...                 ...   \n",
       "58971   58972       99985   176670 2181-01-27 02:47:00 2181-02-12 17:05:00   \n",
       "58972   58973       99991   151118 2184-12-24 08:30:00 2185-01-05 12:15:00   \n",
       "58973   58974       99992   197084 2144-07-25 18:03:00 2144-07-28 17:56:00   \n",
       "58974   58975       99995   137810 2147-02-08 08:00:00 2147-02-11 13:15:00   \n",
       "58975   58976       99999   113369 2117-12-30 07:15:00 2118-01-04 16:30:00   \n",
       "\n",
       "      DEATHTIME ADMISSION_TYPE         ADMISSION_LOCATION  \\\n",
       "1           NaT      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "2           NaT      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "4           NaT       ELECTIVE  PHYS REFERRAL/NORMAL DELI   \n",
       "9           NaT      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "11          NaT      EMERGENCY  TRANSFER FROM HOSP/EXTRAM   \n",
       "...         ...            ...                        ...   \n",
       "58971       NaT      EMERGENCY       EMERGENCY ROOM ADMIT   \n",
       "58972       NaT       ELECTIVE  PHYS REFERRAL/NORMAL DELI   \n",
       "58973       NaT      EMERGENCY  CLINIC REFERRAL/PREMATURE   \n",
       "58974       NaT       ELECTIVE  PHYS REFERRAL/NORMAL DELI   \n",
       "58975       NaT       ELECTIVE  PHYS REFERRAL/NORMAL DELI   \n",
       "\n",
       "              DISCHARGE_LOCATION INSURANCE  ...            EDREGTIME  \\\n",
       "1                            SNF  Medicare  ...  2101-10-20 17:09:00   \n",
       "2      HOME WITH HOME IV PROVIDR   Private  ...  2191-03-15 13:10:00   \n",
       "4               HOME HEALTH CARE  Medicare  ...                  NaN   \n",
       "9               HOME HEALTH CARE   Private  ...  2178-04-15 20:46:00   \n",
       "11              HOME HEALTH CARE  Medicaid  ...                  NaN   \n",
       "...                          ...       ...  ...                  ...   \n",
       "58971           HOME HEALTH CARE   Private  ...  2181-01-26 23:35:00   \n",
       "58972                       HOME   Private  ...                  NaN   \n",
       "58973                        SNF  Medicare  ...  2144-07-25 13:40:00   \n",
       "58974                       HOME  Medicare  ...                  NaN   \n",
       "58975                        SNF  Medicare  ...                  NaN   \n",
       "\n",
       "                 EDOUTTIME                            DIAGNOSIS  \\\n",
       "1      2101-10-20 19:24:00                          HYPOTENSION   \n",
       "2      2191-03-16 01:10:00  FEVER,DEHYDRATION,FAILURE TO THRIVE   \n",
       "4                      NaN            CHRONIC RENAL FAILURE/SDA   \n",
       "9      2178-04-16 06:53:00                           BRAIN MASS   \n",
       "11                     NaN              CORONARY ARTERY DISEASE   \n",
       "...                    ...                                  ...   \n",
       "58971  2181-01-27 04:18:00                                FEVER   \n",
       "58972                  NaN                   DIVERTICULITIS/SDA   \n",
       "58973  2144-07-25 18:50:00           RETROPERITONEAL HEMORRHAGE   \n",
       "58974                  NaN        ABDOMINAL AORTIC ANEURYSM/SDA   \n",
       "58975                  NaN                SPONDYLOLISTHESIS/SDA   \n",
       "\n",
       "      HOSPITAL_EXPIRE_FLAG HAS_CHARTEVENTS_DATA NEXT_ADMITTIME  \\\n",
       "1                        0                    1            NaT   \n",
       "2                        0                    1            NaT   \n",
       "4                        0                    1            NaT   \n",
       "9                        0                    1            NaT   \n",
       "11                       0                    1            NaT   \n",
       "...                    ...                  ...            ...   \n",
       "58971                    0                    1            NaT   \n",
       "58972                    0                    1            NaT   \n",
       "58973                    0                    1            NaT   \n",
       "58974                    0                    1            NaT   \n",
       "58975                    0                    1            NaT   \n",
       "\n",
       "      NEXT_ADMISSION_TYPE  DAYS_NEXT_ADMIT  OUTPUT_LABEL   DURATION  \n",
       "1                     NaN              NaN             0  10.784722  \n",
       "2                     NaN              NaN             0   7.759028  \n",
       "4                     NaN              NaN             0  16.364583  \n",
       "9                     NaN              NaN             0  25.529167  \n",
       "11                    NaN              NaN             0   6.855556  \n",
       "...                   ...              ...           ...        ...  \n",
       "58971                 NaN              NaN             0  16.595833  \n",
       "58972                 NaN              NaN             0  12.156250  \n",
       "58973                 NaN              NaN             0   2.995139  \n",
       "58974                 NaN              NaN             0   3.218750  \n",
       "58975                 NaN              NaN             0   5.385417  \n",
       "\n",
       "[45321 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0ee092",
   "metadata": {},
   "source": [
    "### NOTEEVENTS.CSV\n",
    "\n",
    "For discharge summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed0856a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rx/lt7qchz54wlcnz8s602v0kn80000gn/T/ipykernel_8941/2636703041.py:6: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df_adm_notes.ADMITTIME_C = df_adm_notes.ADMITTIME.apply(lambda x: str(x).split(' ')[0])\n"
     ]
    }
   ],
   "source": [
    "df_notes = df_notes.sort_values(by=['SUBJECT_ID','HADM_ID','CHARTDATE'])\n",
    "df_adm_notes = pd.merge(df_adm[['SUBJECT_ID','HADM_ID','ADMITTIME','DISCHTIME','DAYS_NEXT_ADMIT','NEXT_ADMITTIME','ADMISSION_TYPE','DEATHTIME','OUTPUT_LABEL','DURATION']],\n",
    "                        df_notes[['SUBJECT_ID','HADM_ID','CHARTDATE','TEXT','CATEGORY']],\n",
    "                        on = ['SUBJECT_ID','HADM_ID'],\n",
    "                        how = 'left')\n",
    "df_adm_notes.ADMITTIME_C = df_adm_notes.ADMITTIME.apply(lambda x: str(x).split(' ')[0])\n",
    "\n",
    "df_adm_notes['ADMITTIME_C'] = pd.to_datetime(df_adm_notes.ADMITTIME_C, format = '%Y-%m-%d', errors = 'coerce')\n",
    "df_adm_notes['CHARTDATE'] = pd.to_datetime(df_adm_notes.CHARTDATE, format = '%Y-%m-%d', errors = 'coerce')\n",
    "df_discharge = df_adm_notes[df_adm_notes['CATEGORY'] == 'Discharge summary']\n",
    "df_discharge = (df_discharge.groupby(['SUBJECT_ID','HADM_ID']).nth(-1)).reset_index()\n",
    "df_discharge = df_discharge[df_discharge['TEXT'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cdb2869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>ADMITTIME</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>DAYS_NEXT_ADMIT</th>\n",
       "      <th>NEXT_ADMITTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>DEATHTIME</th>\n",
       "      <th>OUTPUT_LABEL</th>\n",
       "      <th>DURATION</th>\n",
       "      <th>CHARTDATE</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>ADMITTIME_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>2101-10-20 19:08:00</td>\n",
       "      <td>2101-10-31 13:58:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>10.784722</td>\n",
       "      <td>2101-10-31</td>\n",
       "      <td>Admission Date:  [**2101-10-20**]     Discharg...</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2101-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>185777</td>\n",
       "      <td>2191-03-16 00:28:00</td>\n",
       "      <td>2191-03-23 18:41:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>7.759028</td>\n",
       "      <td>2191-03-23</td>\n",
       "      <td>Admission Date:  [**2191-3-16**]     Discharge...</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2191-03-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>107064</td>\n",
       "      <td>2175-05-30 07:15:00</td>\n",
       "      <td>2175-06-15 16:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>16.364583</td>\n",
       "      <td>2175-06-15</td>\n",
       "      <td>Admission Date: [**2175-5-30**]        Dischar...</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2175-05-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>194540</td>\n",
       "      <td>2178-04-16 06:18:00</td>\n",
       "      <td>2178-05-11 19:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>25.529167</td>\n",
       "      <td>2178-05-11</td>\n",
       "      <td>Admission Date:  [**2178-4-16**]              ...</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2178-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>143045</td>\n",
       "      <td>2167-01-08 18:43:00</td>\n",
       "      <td>2167-01-15 15:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>6.855556</td>\n",
       "      <td>2167-01-15</td>\n",
       "      <td>Name:  [**Known lastname 9900**], [**Known fir...</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2167-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43875</th>\n",
       "      <td>99985</td>\n",
       "      <td>176670</td>\n",
       "      <td>2181-01-27 02:47:00</td>\n",
       "      <td>2181-02-12 17:05:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>16.595833</td>\n",
       "      <td>2181-02-12</td>\n",
       "      <td>Admission Date:  [**2181-1-27**]              ...</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2181-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43876</th>\n",
       "      <td>99991</td>\n",
       "      <td>151118</td>\n",
       "      <td>2184-12-24 08:30:00</td>\n",
       "      <td>2185-01-05 12:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>12.156250</td>\n",
       "      <td>2185-01-05</td>\n",
       "      <td>Admission Date:  [**2184-12-24**]             ...</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2184-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43877</th>\n",
       "      <td>99992</td>\n",
       "      <td>197084</td>\n",
       "      <td>2144-07-25 18:03:00</td>\n",
       "      <td>2144-07-28 17:56:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>2.995139</td>\n",
       "      <td>2144-07-28</td>\n",
       "      <td>Admission Date:  [**2144-7-25**]              ...</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2144-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43878</th>\n",
       "      <td>99995</td>\n",
       "      <td>137810</td>\n",
       "      <td>2147-02-08 08:00:00</td>\n",
       "      <td>2147-02-11 13:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>3.218750</td>\n",
       "      <td>2147-02-11</td>\n",
       "      <td>Admission Date:  [**2147-2-8**]              D...</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2147-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43879</th>\n",
       "      <td>99999</td>\n",
       "      <td>113369</td>\n",
       "      <td>2117-12-30 07:15:00</td>\n",
       "      <td>2118-01-04 16:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>ELECTIVE</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>5.385417</td>\n",
       "      <td>2118-01-04</td>\n",
       "      <td>Admission Date:  [**2117-12-30**]             ...</td>\n",
       "      <td>Discharge summary</td>\n",
       "      <td>2117-12-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43880 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SUBJECT_ID  HADM_ID           ADMITTIME           DISCHTIME  \\\n",
       "0               3   145834 2101-10-20 19:08:00 2101-10-31 13:58:00   \n",
       "1               4   185777 2191-03-16 00:28:00 2191-03-23 18:41:00   \n",
       "2               6   107064 2175-05-30 07:15:00 2175-06-15 16:00:00   \n",
       "3              11   194540 2178-04-16 06:18:00 2178-05-11 19:00:00   \n",
       "4              13   143045 2167-01-08 18:43:00 2167-01-15 15:15:00   \n",
       "...           ...      ...                 ...                 ...   \n",
       "43875       99985   176670 2181-01-27 02:47:00 2181-02-12 17:05:00   \n",
       "43876       99991   151118 2184-12-24 08:30:00 2185-01-05 12:15:00   \n",
       "43877       99992   197084 2144-07-25 18:03:00 2144-07-28 17:56:00   \n",
       "43878       99995   137810 2147-02-08 08:00:00 2147-02-11 13:15:00   \n",
       "43879       99999   113369 2117-12-30 07:15:00 2118-01-04 16:30:00   \n",
       "\n",
       "       DAYS_NEXT_ADMIT NEXT_ADMITTIME ADMISSION_TYPE DEATHTIME  OUTPUT_LABEL  \\\n",
       "0                  NaN            NaT      EMERGENCY       NaT             0   \n",
       "1                  NaN            NaT      EMERGENCY       NaT             0   \n",
       "2                  NaN            NaT       ELECTIVE       NaT             0   \n",
       "3                  NaN            NaT      EMERGENCY       NaT             0   \n",
       "4                  NaN            NaT      EMERGENCY       NaT             0   \n",
       "...                ...            ...            ...       ...           ...   \n",
       "43875              NaN            NaT      EMERGENCY       NaT             0   \n",
       "43876              NaN            NaT       ELECTIVE       NaT             0   \n",
       "43877              NaN            NaT      EMERGENCY       NaT             0   \n",
       "43878              NaN            NaT       ELECTIVE       NaT             0   \n",
       "43879              NaN            NaT       ELECTIVE       NaT             0   \n",
       "\n",
       "        DURATION  CHARTDATE  \\\n",
       "0      10.784722 2101-10-31   \n",
       "1       7.759028 2191-03-23   \n",
       "2      16.364583 2175-06-15   \n",
       "3      25.529167 2178-05-11   \n",
       "4       6.855556 2167-01-15   \n",
       "...          ...        ...   \n",
       "43875  16.595833 2181-02-12   \n",
       "43876  12.156250 2185-01-05   \n",
       "43877   2.995139 2144-07-28   \n",
       "43878   3.218750 2147-02-11   \n",
       "43879   5.385417 2118-01-04   \n",
       "\n",
       "                                                    TEXT           CATEGORY  \\\n",
       "0      Admission Date:  [**2101-10-20**]     Discharg...  Discharge summary   \n",
       "1      Admission Date:  [**2191-3-16**]     Discharge...  Discharge summary   \n",
       "2      Admission Date: [**2175-5-30**]        Dischar...  Discharge summary   \n",
       "3      Admission Date:  [**2178-4-16**]              ...  Discharge summary   \n",
       "4      Name:  [**Known lastname 9900**], [**Known fir...  Discharge summary   \n",
       "...                                                  ...                ...   \n",
       "43875  Admission Date:  [**2181-1-27**]              ...  Discharge summary   \n",
       "43876  Admission Date:  [**2184-12-24**]             ...  Discharge summary   \n",
       "43877  Admission Date:  [**2144-7-25**]              ...  Discharge summary   \n",
       "43878  Admission Date:  [**2147-2-8**]              D...  Discharge summary   \n",
       "43879  Admission Date:  [**2117-12-30**]             ...  Discharge summary   \n",
       "\n",
       "      ADMITTIME_C  \n",
       "0      2101-10-20  \n",
       "1      2191-03-16  \n",
       "2      2175-05-30  \n",
       "3      2178-04-16  \n",
       "4      2167-01-08  \n",
       "...           ...  \n",
       "43875  2181-01-27  \n",
       "43876  2184-12-24  \n",
       "43877  2144-07-25  \n",
       "43878  2147-02-08  \n",
       "43879  2117-12-30  \n",
       "\n",
       "[43880 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_discharge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c46fb7",
   "metadata": {},
   "source": [
    "For clinical notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3244ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def less_n_days_data(df_adm_notes, n):\n",
    "    df_less_n = df_adm_notes[\n",
    "        ((df_adm_notes['CHARTDATE'] - df_adm_notes['ADMITTIME_C']).dt.total_seconds() / (24 * 60 * 60)) < n]\n",
    "    df_less_n = df_less_n[df_less_n['TEXT'].notnull()]\n",
    "    df_concat = pd.DataFrame(df_less_n.groupby('HADM_ID')['TEXT'].apply(lambda x: \"%s\" % ' '.join(x))).reset_index()\n",
    "    df_concat['OUTPUT_LABEL'] = df_concat['HADM_ID'].apply(\n",
    "        lambda x: df_less_n[df_less_n['HADM_ID'] == x].OUTPUT_LABEL.values[0])\n",
    "    \n",
    "    return df_concat\n",
    "\n",
    "df_less_2 = less_n_days_data(df_adm_notes, 2)\n",
    "df_less_3 = less_n_days_data(df_adm_notes, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f527723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df_less_n):\n",
    "    def preprocess(x):\n",
    "        y = re.sub('\\\\[(.*?)\\\\]', '', x)\n",
    "        y = re.sub('[0-9]+\\.', '', y)  \n",
    "        y = re.sub('dr\\.', 'doctor', y)\n",
    "        y = re.sub('m\\.d\\.', 'md', y)\n",
    "        y = re.sub('admission date:', '', y)\n",
    "        y = re.sub('discharge date:', '', y)\n",
    "        y = re.sub('--|__|==', '', y)\n",
    "        return y\n",
    "\n",
    "    df_less_n['TEXT'] = df_less_n['TEXT'].fillna(' ')\n",
    "    df_less_n['TEXT'] = df_less_n['TEXT'].str.replace('\\n', ' ')\n",
    "    df_less_n['TEXT'] = df_less_n['TEXT'].str.replace('\\r', ' ')\n",
    "    df_less_n['TEXT'] = df_less_n['TEXT'].apply(str.strip)\n",
    "    df_less_n['TEXT'] = df_less_n['TEXT'].str.lower()\n",
    "\n",
    "    df_less_n['TEXT'] = df_less_n['TEXT'].apply(lambda x: preprocess1(x))\n",
    "\n",
    "    # to get 318 words chunks for readmission tasks\n",
    "    df_len = len(df_less_n)\n",
    "    want = pd.DataFrame({'ID': [], 'TEXT': [], 'Label': []})\n",
    "    for i in tqdm(range(df_len)):\n",
    "        x = df_less_n.TEXT.iloc[i].split()\n",
    "        n = int(len(x) / 318)\n",
    "        for j in range(n):\n",
    "            want = want.append({'TEXT': ' '.join(x[j * 318:(j + 1) * 318]), 'Label': df_less_n.OUTPUT_LABEL.iloc[i],\n",
    "                                'ID': df_less_n.HADM_ID.iloc[i]}, ignore_index=True)\n",
    "        if len(x) % 318 > 10:\n",
    "            want = want.append({'TEXT': ' '.join(x[-(len(x) % 318):]), 'Label': df_less_n.OUTPUT_LABEL.iloc[i],\n",
    "                                'ID': df_less_n.HADM_ID.iloc[i]}, ignore_index=True)\n",
    "\n",
    "    return want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58964139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_discharge = preprocessing(df_discharge)\n",
    "# df_less_2 = preprocessing(df_less_2)\n",
    "# df_less_3 = preprocessing(df_less_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbad4143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_discharge.to_pickle(\"ablation_models/updated_transformer/df_discharge.pkl\")\n",
    "# df_less_2.to_pickle(\"ablation_models/updated_transformer/df_2days.pkl\")\n",
    "# df_less_3.to_pickle(\"ablation_models/updated_transformer/df_3days.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65b2ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discharge = pd.read_pickle('./ablation_models/updated_transformer/df_discharge.pkl')\n",
    "df_less_2 = pd.read_pickle('./ablation_models/updated_transformer/df_2days.pkl')\n",
    "df_less_3 = pd.read_pickle('./ablation_models/updated_transformer/df_3days.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0b70b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216954, 3) (277443, 3) (385724, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_discharge.shape, df_less_2.shape, df_less_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93906c48",
   "metadata": {},
   "source": [
    "## Create Train/Val/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34eb1d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "readmit_ID = df_adm[df_adm.OUTPUT_LABEL == 1].HADM_ID\n",
    "not_readmit_ID = df_adm[df_adm.OUTPUT_LABEL == 0].HADM_ID\n",
    "not_readmit_ID_use = not_readmit_ID.sample(n=len(readmit_ID), random_state=1)\n",
    "id_val_test_t = readmit_ID.sample(frac=0.2, random_state=1)\n",
    "id_val_test_f = not_readmit_ID_use.sample(frac=0.2, random_state=1)\n",
    "\n",
    "id_train_t = readmit_ID.drop(id_val_test_t.index)\n",
    "id_train_f = not_readmit_ID_use.drop(id_val_test_f.index)\n",
    "\n",
    "id_val_t = id_val_test_t.sample(frac=0.5, random_state=1)\n",
    "id_test_t = id_val_test_t.drop(id_val_t.index)\n",
    "\n",
    "id_val_f = id_val_test_f.sample(frac=0.5, random_state=1)\n",
    "id_test_f = id_val_test_f.drop(id_val_f.index)\n",
    "\n",
    "id_test = pd.concat([id_test_t, id_test_f])\n",
    "test_id_label = pd.DataFrame(data=list(zip(id_test, [1] * len(id_test_t) + [0] * len(id_test_f))),\n",
    "                             columns=['id', 'label'])\n",
    "\n",
    "id_val = pd.concat([id_val_t, id_val_f])\n",
    "val_id_label = pd.DataFrame(data=list(zip(id_val, [1] * len(id_val_t) + [0] * len(id_val_f))), columns=['id', 'label'])\n",
    "\n",
    "id_train = pd.concat([id_train_t, id_train_f])\n",
    "train_id_label = pd.DataFrame(data=list(zip(id_train, [1] * len(id_train_t) + [0] * len(id_train_f))),\n",
    "                              columns=['id', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5ef0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_train = df_discharge[df_discharge.ID.isin(train_id_label.id)]\n",
    "discharge_val = df_discharge[df_discharge.ID.isin(val_id_label.id)]\n",
    "discharge_test = df_discharge[df_discharge.ID.isin(test_id_label.id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ada22e5",
   "metadata": {},
   "source": [
    "### For Discharge Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07ff07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([not_readmit_ID_use, not_readmit_ID])\n",
    "df = df.drop_duplicates(keep=False)\n",
    "(pd.Index(df).intersection(pd.Index(not_readmit_ID_use))).values\n",
    "\n",
    "not_readmit_ID_more = df.sample(n=400, random_state=1)\n",
    "\n",
    "discharge_train_snippets = pd.concat([df_discharge[df_discharge.ID.isin(not_readmit_ID_more)], discharge_train])\n",
    "discharge_train_snippets = discharge_train_snippets.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "discharge_train_snippets.Label.value_counts()\n",
    "discharge_train_snippets.to_csv('./data/discharge/train.csv')\n",
    "discharge_val.to_csv('./data/discharge/val.csv')\n",
    "discharge_test.to_csv('./data/discharge/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c56902a",
   "metadata": {},
   "source": [
    "### For Early Clinical Notes - 3 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09bc53bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_train = df_less_3[df_less_3.ID.isin(train_id_label.id)]\n",
    "not_readmit_ID_more = df.sample(n=500, random_state=1)\n",
    "early_train_snippets = pd.concat([df_less_3[df_less_3.ID.isin(not_readmit_ID_more)], early_train])\n",
    "early_train_snippets = early_train_snippets.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "early_train_snippets.to_csv('./data/3days/train.csv')\n",
    "\n",
    "early_val = df_less_3[df_less_3.ID.isin(val_id_label.id)]\n",
    "early_val.to_csv('./data/3days/val.csv')\n",
    "\n",
    "actionable_ID_3days = df_adm[df_adm['DURATION'] >= 3].HADM_ID\n",
    "test_actionable_id_label = test_id_label[test_id_label.id.isin(actionable_ID_3days)]\n",
    "early_test = df_less_3[df_less_3.ID.isin(test_actionable_id_label.id)]\n",
    "\n",
    "early_test.to_csv('./data/3days/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af04a50",
   "metadata": {},
   "source": [
    "### For Early Clinical Notes - 2 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e410bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "actionable_ID_2days = df_adm[df_adm['DURATION'] >= 2].HADM_ID\n",
    "test_actionable_id_label_2days = test_id_label[test_id_label.id.isin(actionable_ID_2days)]\n",
    "early_test_2days = df_less_2[df_less_2.ID.isin(test_actionable_id_label_2days.id)]\n",
    "early_test_2days.to_csv('./data/2days/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da7a13f",
   "metadata": {},
   "source": [
    "## Early Notes\n",
    "\n",
    "### Run Model for Readmission Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fef1c8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/15/2022 21:14:00 - INFO - __main__ -   device: cpu n_gpu: 0 Distributed training: False\n"
     ]
    }
   ],
   "source": [
    "local_rank = -1\n",
    "no_cuda = False # Set flag to True to disable CUDA\n",
    "if local_rank == -1 or no_cuda:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "else:\n",
    "    device = torch.device(\"cuda\", local_rank)\n",
    "    n_gpu = 1\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s', \n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"device: %s n_gpu: %d Distributed training: %r\", device, n_gpu, bool(local_rank != -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d73e946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_accumulation_steps = 1\n",
    "if gradient_accumulation_steps < 1:\n",
    "    raise ValueError(\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\".format(gradient_accumulation_steps))\n",
    "\n",
    "train_batch_size = 32\n",
    "train_batch_size = int(train_batch_size / gradient_accumulation_steps)\n",
    "seed= 42\n",
    "do_train = False\n",
    "do_eval = True\n",
    "output_dir = './results/ablation/transformer/result_early' \n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "if not do_train and not do_eval:\n",
    "    raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
    "\n",
    "if os.path.exists(output_dir) and os.listdir(output_dir):\n",
    "    raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(output_dir))\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f188038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "396c8d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(object):\n",
    "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @classmethod\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "        with open(input_file, \"r\") as f:\n",
    "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
    "            lines = []\n",
    "            for line in reader:\n",
    "                lines.append(line)\n",
    "            return lines\n",
    "        \n",
    "    @classmethod\n",
    "    def _read_csv(cls, input_file):\n",
    "        \"\"\"Reads a comma separated value file.\"\"\"\n",
    "        file=pd.read_csv(input_file)\n",
    "        lines=zip(file.ID,file.TEXT,file.Label)\n",
    "        return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40469715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class readmissionProcessor(DataProcessor):\n",
    "    def get_train_examples(self, data_dir):\n",
    "        logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, \"train.csv\")))\n",
    "        return self._create_examples(self._read_csv(os.path.join(data_dir, \"train.csv\")), \"train\")\n",
    "    \n",
    "    def get_dev_examples(self, data_dir):\n",
    "        return self._create_examples(self._read_csv(os.path.join(data_dir, \"val.csv\")), \"val\")\n",
    "    \n",
    "    def get_test_examples(self, data_dir):\n",
    "        return self._create_examples(self._read_csv(os.path.join(data_dir, \"test.csv\")), \"test\")\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return [\"0\", \"1\"]\n",
    "    \n",
    "    def _create_examples(self, lines, set_type):\n",
    "        \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
    "        examples = []\n",
    "        for (i, line) in enumerate(lines):\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = line[1]\n",
    "            label = str(int(line[2])) \n",
    "            examples.append(InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14b61cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = readmissionProcessor()\n",
    "label_list = processor.get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18deb155",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') \n",
    "data_dir = './data/3days/'\n",
    "train_examples = None\n",
    "num_train_steps = None\n",
    "if do_train:\n",
    "    train_examples = processor.get_train_examples(data_dir)\n",
    "    num_train_steps = int(\n",
    "        len(train_examples) / train_batch_size / gradient_accumulation_steps * num_train_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c389bc2",
   "metadata": {},
   "source": [
    "### Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dcae724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/15/2022 15:19:39 - INFO - modeling_readmission -   loading archive file ./model/early_readmission\n",
      "04/15/2022 15:19:39 - INFO - modeling_readmission -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('./')\n",
    "bert_model='./model/early_readmission'\n",
    "model = BertForSequenceClassification.from_pretrained(bert_model, 1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2341f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if local_rank != -1:\n",
    "    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[local_rank], output_device=local_rank)\n",
    "elif n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35b6af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_on_cpu = False\n",
    "learning_rate = 5e-5\n",
    "warmup_proportion = 0.1\n",
    "global_step = 0\n",
    "train_loss=100000\n",
    "number_training_steps=1\n",
    "global_step_check=0\n",
    "train_loss_history=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c133eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "readmission_mode = 'early'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed3ab132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_score(df, score, readmission_mode, output_dir):\n",
    "    df['pred_score'] = score\n",
    "    df_sort = df.sort_values(by=['ID'])\n",
    "    #score \n",
    "    temp = (df_sort.groupby(['ID'])['pred_score'].agg(max)+df_sort.groupby(['ID'])['pred_score'].agg(sum)/2)/(1+df_sort.groupby(['ID'])['pred_score'].agg(len)/2)\n",
    "    x = df_sort.groupby(['ID'])['Label'].agg(np.min).values\n",
    "    df_out = pd.DataFrame({'logits': temp.values, 'ID': x})\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(x, temp.values)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.plot(fpr, tpr, label='Val (area = {:.3f})'.format(auc_score))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    string = 'auroc_clinicalbert_'+readmission_mode+'.png'\n",
    "    plt.savefig(os.path.join(output_dir, string))\n",
    "\n",
    "    return fpr, tpr, df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e6c5b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_curve_plot(y, y_score, readmission_mode, output_dir):\n",
    "    precision, recall, _ = precision_recall_curve(y, y_score)\n",
    "    area = auc(recall,precision)\n",
    "    step_kwargs = ({'step': 'post'}\n",
    "                   if 'step' in signature(plt.fill_between).parameters\n",
    "                   else {})\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall curve: AUC={0:0.2f}'.format(area))\n",
    "    \n",
    "    string = 'auprc_clinicalbert_'+readmission_mode+'.png'\n",
    "\n",
    "    plt.savefig(os.path.join(output_dir, string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "959c90f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_pr_curve(df, score, readmission_mode, output_dir):\n",
    "    df['pred_score'] = score\n",
    "    df_sort = df.sort_values(by=['ID'])\n",
    "    #score \n",
    "    temp = (df_sort.groupby(['ID'])['pred_score'].agg(max)+df_sort.groupby(['ID'])['pred_score'].agg(sum)/2)/(1+df_sort.groupby(['ID'])['pred_score'].agg(len)/2)\n",
    "    y = df_sort.groupby(['ID'])['Label'].agg(np.min).values\n",
    "    \n",
    "    precision, recall, thres = precision_recall_curve(y, temp)\n",
    "    pr_thres = pd.DataFrame(data =  list(zip(precision, recall, thres)), columns = ['prec','recall','thres'])\n",
    "    vote_df = pd.DataFrame(data =  list(zip(temp, y)), columns = ['score','label'])\n",
    "    \n",
    "    pr_curve_plot(y, temp, readmission_mode, output_dir)\n",
    "    \n",
    "    temp = pr_thres[pr_thres.prec > 0.799999].reset_index()\n",
    "    \n",
    "    rp80 = 0\n",
    "    if temp.size == 0:\n",
    "        print('Test Sample too small or RP80=0')\n",
    "    else:\n",
    "        rp80 = temp.iloc[0].recall\n",
    "        print('Recall at Precision of 80 is {}', rp80)\n",
    "\n",
    "    return rp80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55961e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
    "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "\n",
    "    # This is a simple heuristic which will always truncate the longer sequence\n",
    "    # one token at a time. This makes more sense than truncating an equal percent\n",
    "    # of tokens from each, since if one sequence is very short then each token\n",
    "    # that's truncated likely contains more information than a longer sequence.\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_length:\n",
    "            break\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            tokens_a.pop()\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1660d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "\n",
    "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "    label_map = {}\n",
    "    for (i, label) in enumerate(label_list):\n",
    "        label_map[label] = i\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "\n",
    "        tokens_b = None\n",
    "        if example.text_b:\n",
    "            tokens_b = tokenizer.tokenize(example.text_b)\n",
    "\n",
    "        if tokens_b:\n",
    "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "        else:\n",
    "            if len(tokens_a) > max_seq_length - 2:\n",
    "                tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "\n",
    "        tokens = []\n",
    "        segment_ids = []\n",
    "        tokens.append(\"[CLS]\")\n",
    "        segment_ids.append(0)\n",
    "        for token in tokens_a:\n",
    "            tokens.append(token)\n",
    "            segment_ids.append(0)\n",
    "        tokens.append(\"[SEP]\")\n",
    "        segment_ids.append(0)\n",
    "\n",
    "        if tokens_b:\n",
    "            for token in tokens_b:\n",
    "                tokens.append(token)\n",
    "                segment_ids.append(1)\n",
    "            tokens.append(\"[SEP]\")\n",
    "            segment_ids.append(1)\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "            segment_ids.append(0)\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        #print (example.label)\n",
    "        label_id = label_map[example.label]\n",
    "        if ex_index < 5:\n",
    "            logger.info(\"*** Example ***\")\n",
    "            logger.info(\"guid: %s\" % (example.guid))\n",
    "            logger.info(\"tokens: %s\" % \" \".join(\n",
    "                    [str(x) for x in tokens]))\n",
    "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "            logger.info(\n",
    "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "            logger.info(\"label: %s (id = %d)\" % (example.label, label_id))\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_id=label_id))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa0bd976",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128\n",
    "eval_batch_size = 2\n",
    "\n",
    "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "    label_map = {}\n",
    "    for (i, label) in enumerate(label_list):\n",
    "        label_map[label] = i\n",
    "\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        tokens_a = tokenizer.tokenize(example.text_a)\n",
    "\n",
    "        tokens_b = None\n",
    "        if example.text_b:\n",
    "            tokens_b = tokenizer.tokenize(example.text_b)\n",
    "\n",
    "        if tokens_b:\n",
    "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "        else:\n",
    "            if len(tokens_a) > max_seq_length - 2:\n",
    "                tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "\n",
    "        tokens = []\n",
    "        segment_ids = []\n",
    "        tokens.append(\"[CLS]\")\n",
    "        segment_ids.append(0)\n",
    "        for token in tokens_a:\n",
    "            tokens.append(token)\n",
    "            segment_ids.append(0)\n",
    "        tokens.append(\"[SEP]\")\n",
    "        segment_ids.append(0)\n",
    "\n",
    "        if tokens_b:\n",
    "            for token in tokens_b:\n",
    "                tokens.append(token)\n",
    "                segment_ids.append(1)\n",
    "            tokens.append(\"[SEP]\")\n",
    "            segment_ids.append(1)\n",
    "\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        while len(input_ids) < max_seq_length:\n",
    "            input_ids.append(0)\n",
    "            input_mask.append(0)\n",
    "            segment_ids.append(0)\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "        #print (example.label)\n",
    "        label_id = label_map[example.label]\n",
    "        if ex_index < 5:\n",
    "            logger.info(\"*** Example ***\")\n",
    "            logger.info(\"guid: %s\" % (example.guid))\n",
    "            logger.info(\"tokens: %s\" % \" \".join(\n",
    "                    [str(x) for x in tokens]))\n",
    "            logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "            logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "            logger.info(\n",
    "                    \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "            logger.info(\"label: %s (id = %d)\" % (example.label, label_id))\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_id=label_id))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a15bc5",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e481260b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/15/2022 15:19:45 - INFO - __main__ -   *** Example ***\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   guid: test-0\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   tokens: [CLS] sin ##us ta ##chy ##card ##ia . generalized low voltage . delayed r wave progression with late pre ##cor ##dial q ##rs transition . findings are non - specific . clinical correlation is suggested . since the previous tracing of same date sin ##us ta ##chy ##card ##ia rate is faster . tracing # 1 sin ##us rhythm . delayed r wave progression with late pre ##cor ##dial q ##rs transition . generalized low q ##rs voltage . findings are non - specific . clinical correlation is suggested . since the previous tracing of the rate is faster and voltage is lower . title : 45 y / o man with h ##x of et ##oh ci ##rr ##hosis who arrived for planned liver transplant . [SEP]\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   input_ids: 101 8254 2271 11937 11714 11522 2401 1012 18960 2659 10004 1012 8394 1054 4400 14967 2007 2397 3653 27108 27184 1053 2869 6653 1012 9556 2024 2512 1011 3563 1012 6612 16902 2003 4081 1012 2144 1996 3025 16907 1997 2168 3058 8254 2271 11937 11714 11522 2401 3446 2003 5514 1012 16907 1001 1015 8254 2271 6348 1012 8394 1054 4400 14967 2007 2397 3653 27108 27184 1053 2869 6653 1012 18960 2659 1053 2869 10004 1012 9556 2024 2512 1011 3563 1012 6612 16902 2003 4081 1012 2144 1996 3025 16907 1997 1996 3446 2003 5514 1998 10004 2003 2896 1012 2516 1024 3429 1061 1013 1051 2158 2007 1044 2595 1997 3802 11631 25022 12171 25229 2040 3369 2005 3740 11290 22291 1012 102\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   label: 1 (id = 1)\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   *** Example ***\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   guid: test-1\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   tokens: [CLS] pa and lateral chest radio ##graphs . comparison : compared to radio ##graph from . findings : heart size is moderately enlarged , similar to prior study . there is mild pulmonary vascular redistribution . there is stable small left pl ##eur ##al e ##ff ##usion . interval removal of right pic ##c line . impression : card ##iom ##ega ##ly . no pneumonia . small left pl ##eur ##al e ##ff ##usion . 11 : 26 pm chest ( portable ap ) ; - 76 by same physician # reason : s / p ol ##t . eva ##l for collapse , over ##load admitting diagnosis : liver tx medical condition : 45 year old man des ##at ##uration ##s , int ##uba ##ted reason [SEP]\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   input_ids: 101 6643 1998 11457 3108 2557 27341 1012 7831 1024 4102 2000 2557 14413 2013 1012 9556 1024 2540 2946 2003 17844 11792 1010 2714 2000 3188 2817 1012 2045 2003 10256 21908 21449 25707 1012 2045 2003 6540 2235 2187 20228 11236 2389 1041 4246 14499 1012 13483 8208 1997 2157 27263 2278 2240 1012 8605 1024 4003 18994 29107 2135 1012 2053 18583 1012 2235 2187 20228 11236 2389 1041 4246 14499 1012 2340 1024 2656 7610 3108 1006 12109 9706 1007 1025 1011 6146 2011 2168 7522 1001 3114 1024 1055 1013 1052 19330 2102 1012 9345 2140 2005 7859 1010 2058 11066 17927 11616 1024 11290 19067 2966 4650 1024 3429 2095 2214 2158 4078 4017 18924 2015 1010 20014 19761 3064 3114 102\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   label: 1 (id = 1)\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   *** Example ***\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   guid: test-2\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   tokens: [CLS] cat ##het ##er projects over the right vent ##ric ##le below the out ##flow tract . no media ##sti ##nal widening or app ##re ##cia ##ble pl ##eur ##al e ##ff ##usion . no p ##ne ##um ##otho ##ra ##x . et tube is at the thor ##ac ##ic inlet . sin ##us rhythm with border ##line sin ##us ta ##chy ##card ##ia . generalized low voltage . delayed r wave progression with late pre ##cor ##dial q ##rs transition . findings are non - specific . clinical correlation is suggested . since the previous tracing of sin ##us ta ##chy ##card ##ia rate is slower and right pre ##cor ##dial lead t wave changes appear more prominent . tracing # 2 renal failure , acute [SEP]\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   input_ids: 101 4937 27065 2121 3934 2058 1996 2157 18834 7277 2571 2917 1996 2041 12314 12859 1012 2053 2865 16643 12032 17973 2030 10439 2890 7405 3468 20228 11236 2389 1041 4246 14499 1012 2053 1052 2638 2819 29288 2527 2595 1012 3802 7270 2003 2012 1996 15321 6305 2594 15824 1012 8254 2271 6348 2007 3675 4179 8254 2271 11937 11714 11522 2401 1012 18960 2659 10004 1012 8394 1054 4400 14967 2007 2397 3653 27108 27184 1053 2869 6653 1012 9556 2024 2512 1011 3563 1012 6612 16902 2003 4081 1012 2144 1996 3025 16907 1997 8254 2271 11937 11714 11522 2401 3446 2003 12430 1998 2157 3653 27108 27184 2599 1056 4400 3431 3711 2062 4069 1012 16907 1001 1016 25125 4945 1010 11325 102\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   label: 1 (id = 1)\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   *** Example ***\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   guid: test-3\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   tokens: [CLS] intake in products from or and here in sic ##u labs q 4 hr response : no response from fur ##ose ##mide labs showing cr taking bump from 0 to 8 plan : continue to monitor at ##n continue to monitor cr / bun / renal function respiratory failure , acute ( not ar ##ds / ) assessment : pt initially on ac 850 ##x ##14 , 40 % from or an ##esthesia settings ab ##gs getting more al ##kal ##otic post - fur ##ose ##mide doses o ##2 sat ##s ~ 95 % - 97 % briefly dropping o ##2 sat ##s ~ 90 and not rebound ##ing with su ##ction action : ab ##gs drawn q ##2 rt in to evaluate pt with drop [SEP]\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   input_ids: 101 13822 1999 3688 2013 2030 1998 2182 1999 14387 2226 13625 1053 1018 17850 3433 1024 2053 3433 2013 6519 9232 24284 13625 4760 13675 2635 16906 2013 1014 2000 1022 2933 1024 3613 2000 8080 2012 2078 3613 2000 8080 13675 1013 21122 1013 25125 3853 16464 4945 1010 11325 1006 2025 12098 5104 1013 1007 7667 1024 13866 3322 2006 9353 15678 2595 16932 1010 2871 1003 2013 2030 2019 25344 10906 11113 5620 2893 2062 2632 12902 20214 2695 1011 6519 9232 24284 21656 1051 2475 2938 2015 1066 5345 1003 1011 5989 1003 4780 7510 1051 2475 2938 2015 1066 3938 1998 2025 27755 2075 2007 10514 7542 2895 1024 11113 5620 4567 1053 2475 19387 1999 2000 16157 13866 2007 4530 102\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/15/2022 15:19:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   label: 1 (id = 1)\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   *** Example ***\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   guid: test-4\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   tokens: [CLS] hc ##t > 30 ) trans ##fus ##e pt according to goals ? additional pr ##bc ##s to treat hc ##t ~ 26 - 27 for goal > 30 continue pathway sic ##u hp ##i : 45 ##yo m w / et ##oh ci ##rr ##hosis , mel ##d 28 , child class c ci ##rr ##hosis admitted for liver transplant . denies change in health since previous admission 8 / . admitted to for fever ##s , an ##emia , as ##cite ##s , ar ##f . hospital course , treated w / z ##os ##yn for c . per ##fr ##ingen ##s ba ##cter ##emia . para ##cent ##esis negative for sb ##p . e ##g ##d w / grade i var ##ices . [SEP]\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   input_ids: 101 16731 2102 1028 2382 1007 9099 25608 2063 13866 2429 2000 3289 1029 3176 10975 9818 2015 2000 7438 16731 2102 1066 2656 1011 2676 2005 3125 1028 2382 3613 12732 14387 2226 6522 2072 1024 3429 7677 1049 1059 1013 3802 11631 25022 12171 25229 1010 11463 2094 2654 1010 2775 2465 1039 25022 12171 25229 4914 2005 11290 22291 1012 23439 2689 1999 2740 2144 3025 9634 1022 1013 1012 4914 2000 2005 9016 2015 1010 2019 17577 1010 2004 17847 2015 1010 12098 2546 1012 2902 2607 1010 5845 1059 1013 1062 2891 6038 2005 1039 1012 2566 19699 15542 2015 8670 21162 17577 1012 11498 13013 19009 4997 2005 24829 2361 1012 1041 2290 2094 1059 1013 3694 1045 13075 23522 1012 102\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/15/2022 15:19:45 - INFO - __main__ -   label: 1 (id = 1)\n",
      "04/15/2022 15:20:19 - INFO - __main__ -   ***** Running evaluation *****\n",
      "04/15/2022 15:20:19 - INFO - __main__ -     Num examples = 5441\n",
      "04/15/2022 15:20:19 - INFO - __main__ -     Batch size = 2\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2721/2721 [53:39<00:00,  1.18s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/15/2022 16:13:59 - INFO - __main__ -   ***** Eval results *****\n",
      "04/15/2022 16:13:59 - INFO - __main__ -     RP80 = 0.38022813688212925\n",
      "04/15/2022 16:13:59 - INFO - __main__ -     eval_accuracy = 0.621760705752619\n",
      "04/15/2022 16:13:59 - INFO - __main__ -     eval_loss = 0.6304757042277299\n",
      "04/15/2022 16:13:59 - INFO - __main__ -     global_step = 0\n",
      "04/15/2022 16:13:59 - INFO - __main__ -     training loss = 100000.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall at Precision of 80 is {} 0.38022813688212925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_seq_length = 128\n",
    "eval_batch_size = 2\n",
    "\n",
    "m = nn.Sigmoid()\n",
    "if do_eval:\n",
    "    eval_examples = processor.get_test_examples(data_dir)\n",
    "    eval_features = convert_examples_to_features(\n",
    "        eval_examples, label_list, max_seq_length, tokenizer)\n",
    "    logger.info(\"***** Running evaluation *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(eval_examples))\n",
    "    logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    if local_rank == -1:\n",
    "        eval_sampler = SequentialSampler(eval_data)\n",
    "    else:\n",
    "        eval_sampler = DistributedSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    true_labels=[]\n",
    "    pred_labels=[]\n",
    "    logits_history=[]\n",
    "    for input_ids, input_mask, segment_ids, label_ids in tqdm(eval_dataloader):\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        label_ids = label_ids.to(device)\n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss, temp_logits = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "            logits = model(input_ids,segment_ids,input_mask)\n",
    "\n",
    "        logits = torch.squeeze(m(logits)).detach().cpu().numpy()\n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "\n",
    "        outputs = np.asarray([1 if i else 0 for i in (logits.flatten()>=0.5)])\n",
    "        tmp_eval_accuracy=np.sum(outputs == label_ids)\n",
    "\n",
    "        true_labels = true_labels + label_ids.flatten().tolist()\n",
    "        pred_labels = pred_labels + outputs.flatten().tolist()\n",
    "        logits_history = logits_history + logits.flatten().tolist()\n",
    "\n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        nb_eval_examples += input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_examples\n",
    "    df = pd.DataFrame({'logits':logits_history, 'pred_label': pred_labels, 'label':true_labels})\n",
    "\n",
    "    string = 'logits_clinicalbert_'+readmission_mode+'_chunks.csv'\n",
    "    df.to_csv(os.path.join(output_dir, string))\n",
    "\n",
    "    df_test = pd.read_csv(os.path.join(data_dir, \"test.csv\"))\n",
    "\n",
    "    fpr, tpr, df_out = vote_score(df_test, logits_history, readmission_mode, output_dir)\n",
    "\n",
    "    string = 'logits_clinicalbert_'+readmission_mode+'_readmissions.csv'\n",
    "    df_out.to_csv(os.path.join(output_dir,string))\n",
    "\n",
    "    rp80 = vote_pr_curve(df_test, logits_history, readmission_mode, output_dir)\n",
    "\n",
    "    result = {'eval_loss': eval_loss,\n",
    "              'eval_accuracy': eval_accuracy,                 \n",
    "              'global_step': global_step_check,\n",
    "              'training loss': train_loss/number_training_steps,\n",
    "              'RP80': rp80}\n",
    "\n",
    "    output_eval_file = os.path.join(output_dir, \"eval_results.txt\")\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74347b6",
   "metadata": {},
   "source": [
    "## Discharge Notes\n",
    "\n",
    "### Run Model for Readmission Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8d6438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_accumulation_steps = 1\n",
    "if gradient_accumulation_steps < 1:\n",
    "    raise ValueError(\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\".format(gradient_accumulation_steps))\n",
    "\n",
    "train_batch_size = 32\n",
    "train_batch_size = int(train_batch_size / gradient_accumulation_steps)\n",
    "seed= 42\n",
    "do_train = False\n",
    "do_eval = True\n",
    "output_dir1 = './results/ablation/transformer/result_discharge' \n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "if not do_train and not do_eval:\n",
    "    raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
    "\n",
    "if os.path.exists(output_dir1) and os.listdir(output_dir1):\n",
    "    raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(output_dir1))\n",
    "\n",
    "os.makedirs(output_dir1, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ed040dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') \n",
    "data_dir = './data/discharge/'\n",
    "train_examples = None\n",
    "num_train_steps = None\n",
    "if do_train:\n",
    "    train_examples = processor.get_train_examples(data_dir)\n",
    "    num_train_steps = int(\n",
    "        len(train_examples) / train_batch_size / gradient_accumulation_steps * num_train_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31601ae8",
   "metadata": {},
   "source": [
    "### Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "456b968b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/15/2022 21:16:14 - INFO - modeling_readmission -   loading archive file ./model/discharge_readmission\n",
      "04/15/2022 21:16:14 - INFO - modeling_readmission -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path.append('./')\n",
    "bert_model='./model/discharge_readmission'\n",
    "model = BertForSequenceClassification.from_pretrained(bert_model, 1)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4469cc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "readmission_mode1 = 'discharge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c448b78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/15/2022 21:19:30 - INFO - __main__ -   *** Example ***\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   guid: test-0\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   tokens: [CLS] date of birth : sex : f service : medicine all ##er ##gies : hal ##do ##l attending : chief complaint : delta ms , let ##har ##gy , ? sep ##sis . major surgical or invasive procedure : none history of present illness : h ##x obtained per ed notes and sister . hp ##i : 35 ##f with disease who presented today from day ##care after her healthcare providers noted that she was let ##har ##gic . they were initially unable to obtain a blood pressure . the patient was noted to have a very rapid heart rate . vital ##s were finally obtained and were as follows : bp 70 / 50 ( baseline sb ##ps 80 - 90 ) , hr 113 [SEP]\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   input_ids: 101 3058 1997 4182 1024 3348 1024 1042 2326 1024 4200 2035 2121 17252 1024 11085 3527 2140 7052 1024 2708 12087 1024 7160 5796 1010 2292 8167 6292 1010 1029 19802 6190 1012 2350 11707 2030 17503 7709 1024 3904 2381 1997 2556 7355 1024 1044 2595 4663 2566 3968 3964 1998 2905 1012 6522 2072 1024 3486 2546 2007 4295 2040 3591 2651 2013 2154 16302 2044 2014 9871 11670 3264 2008 2016 2001 2292 8167 12863 1012 2027 2020 3322 4039 2000 6855 1037 2668 3778 1012 1996 5776 2001 3264 2000 2031 1037 2200 5915 2540 3446 1012 8995 2015 2020 2633 4663 1998 2020 2004 4076 1024 17531 3963 1013 2753 1006 26163 24829 4523 3770 1011 3938 1007 1010 17850 12104 102\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   label: 1 (id = 1)\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   *** Example ***\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   guid: test-1\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   tokens: [CLS] pneumonia . . echo the left atrium is normal in size . left vent ##ric ##ular wall thickness ##es are normal . the left vent ##ric ##ular cavity is moderately dil ##ated . there is severe global left vent ##ric ##ular h ##yp ##oki ##nes ##is . no masses or th ##rom ##bi are seen in the left vent ##ric ##le . right vent ##ric ##ular sy ##sto ##lic function is border ##line normal . the ao ##rti ##c valve leaflets ( 3 ) appear structurally normal with good leaf ##let excursion and no ao ##rti ##c reg ##urg ##itation . the mit ##ral valve leaflets are structurally normal . moderate ( 2 + ) mit ##ral reg ##urg ##itation is seen . the mit ##ral [SEP]\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   input_ids: 101 18583 1012 1012 9052 1996 2187 26204 2003 3671 1999 2946 1012 2187 18834 7277 7934 2813 14983 2229 2024 3671 1012 1996 2187 18834 7277 7934 17790 2003 17844 29454 4383 1012 2045 2003 5729 3795 2187 18834 7277 7934 1044 22571 23212 5267 2483 1012 2053 11678 2030 16215 21716 5638 2024 2464 1999 1996 2187 18834 7277 2571 1012 2157 18834 7277 7934 25353 16033 10415 3853 2003 3675 4179 3671 1012 1996 20118 28228 2278 10764 27306 1006 1017 1007 3711 29060 3671 2007 2204 7053 7485 26144 1998 2053 20118 28228 2278 19723 12514 18557 1012 1996 10210 7941 10764 27306 2024 29060 3671 1012 8777 1006 1016 1009 1007 10210 7941 19723 12514 18557 2003 2464 1012 1996 10210 7941 102\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   label: 1 (id = 1)\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   *** Example ***\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   guid: test-2\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   tokens: [CLS] may recommend li ##sin ##op ##ril low dose as an out ##patient , follow up in 1 month with card ##iology . p ##na - patient received lev ##aq ##uin , van ##c , flag ##yl and ce ##ft ##ria ##xon ##e in the ed . imaging concerning for pneumonia . - trend le ##uk ##oc ##yt ##osis and fever curve - change una ##sy ##n for coverage of as ##piration p ##na to aug ##ment ##in 500 ##mg po ti ##d today ( ) - blood cultures : pending - urine cultures : ng ##t ##d final . delta ms : per patient ' s pc ##p , . , and pt ' s sister - patient is at baseline . let ##har ##gy may [SEP]\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   input_ids: 101 2089 16755 5622 11493 7361 15928 2659 13004 2004 2019 2041 24343 1010 3582 2039 1999 1015 3204 2007 4003 20569 1012 1052 2532 1011 5776 2363 23310 20784 20023 1010 3158 2278 1010 5210 8516 1998 8292 6199 4360 22500 2063 1999 1996 3968 1012 12126 7175 2005 18583 1012 1011 9874 3393 6968 10085 22123 12650 1998 9016 7774 1011 2689 14477 6508 2078 2005 6325 1997 2004 16781 1052 2532 2000 15476 3672 2378 3156 24798 13433 14841 2094 2651 1006 1007 1011 2668 8578 1024 14223 1011 17996 8578 1024 12835 2102 2094 2345 1012 7160 5796 1024 2566 5776 1005 1055 7473 2361 1010 1012 1010 1998 13866 1005 1055 2905 1011 5776 2003 2012 26163 1012 2292 8167 6292 2089 102\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   label: 1 (id = 1)\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   *** Example ***\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   guid: test-3\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   tokens: [CLS] should develop any chest pain , short ##ness of breath , nausea , vomiting , difficulty eating , cough , fever or any other concerns , please call dr or return to the emergency department follow ##up instructions : please follow up with dr within the next week . dr should set up a follow up with card ##iology within the next month . [SEP]\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   input_ids: 101 2323 4503 2151 3108 3255 1010 2460 2791 1997 3052 1010 19029 1010 24780 1010 7669 5983 1010 19340 1010 9016 2030 2151 2060 5936 1010 3531 2655 2852 2030 2709 2000 1996 5057 2533 3582 6279 8128 1024 3531 3582 2039 2007 2852 2306 1996 2279 2733 1012 2852 2323 2275 2039 1037 3582 2039 2007 4003 20569 2306 1996 2279 3204 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   label: 1 (id = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/15/2022 21:19:30 - INFO - __main__ -   *** Example ***\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   guid: test-4\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   tokens: [CLS] date of birth : sex : f service : medicine all ##er ##gies : pen ##ici ##llins / per ##co ##ce ##t attending : chief complaint : face , left arm and breast swelling major surgical or invasive procedure : intra ##ven ##ous cat ##het ##eri ##zation of sv ##c / iv ##c . history of present illness : 23 year old woman with es ##rd , sl ##e , recently placed pd cat ##het ##er who presents with per ##ior ##bit ##al swelling and hyper ##tens ##ive urgency . of note she was recently admitted for tongue swelling on . at that time she was treated with sol ##u - med ##rol , fa ##mot ##idi ##ne and ben ##ad ##ryl in the emergency room [SEP]\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   input_ids: 101 3058 1997 4182 1024 3348 1024 1042 2326 1024 4200 2035 2121 17252 1024 7279 28775 26655 1013 2566 3597 3401 2102 7052 1024 2708 12087 1024 2227 1010 2187 2849 1998 7388 18348 2350 11707 2030 17503 7709 1024 26721 8159 3560 4937 27065 11124 9276 1997 17917 2278 1013 4921 2278 1012 2381 1997 2556 7355 1024 2603 2095 2214 2450 2007 9686 4103 1010 22889 2063 1010 3728 2872 22851 4937 27065 2121 2040 7534 2007 2566 25346 16313 2389 18348 1998 23760 25808 3512 19353 1012 1997 3602 2016 2001 3728 4914 2005 4416 18348 2006 1012 2012 2008 2051 2016 2001 5845 2007 14017 2226 1011 19960 13153 1010 6904 18938 28173 2638 1998 3841 4215 23320 1999 1996 5057 2282 102\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "04/15/2022 21:19:30 - INFO - __main__ -   label: 1 (id = 1)\n",
      "04/15/2022 21:19:46 - INFO - __main__ -   ***** Running evaluation *****\n",
      "04/15/2022 21:19:46 - INFO - __main__ -     Num examples = 3063\n",
      "04/15/2022 21:19:46 - INFO - __main__ -     Batch size = 2\n",
      "100%|███████████████████████████████████████| 1532/1532 [27:11<00:00,  1.06s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/15/2022 21:46:57 - INFO - __main__ -   ***** Eval results *****\n",
      "04/15/2022 21:46:57 - INFO - __main__ -     RP80 = 0.20689655172413793\n",
      "04/15/2022 21:46:57 - INFO - __main__ -     eval_accuracy = 0.6304276852758733\n",
      "04/15/2022 21:46:57 - INFO - __main__ -     eval_loss = 0.6483550992485515\n",
      "04/15/2022 21:46:57 - INFO - __main__ -     global_step = 0\n",
      "04/15/2022 21:46:57 - INFO - __main__ -     training loss = 100000.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall at Precision of 80 is {} 0.20689655172413793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_seq_length = 128\n",
    "eval_batch_size = 2\n",
    "\n",
    "m = nn.Sigmoid()\n",
    "if do_eval:\n",
    "    eval_examples = processor.get_test_examples(data_dir)\n",
    "    eval_features = convert_examples_to_features(\n",
    "        eval_examples, label_list, max_seq_length, tokenizer)\n",
    "    logger.info(\"***** Running evaluation *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(eval_examples))\n",
    "    logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "    if local_rank == -1:\n",
    "        eval_sampler = SequentialSampler(eval_data)\n",
    "    else:\n",
    "        eval_sampler = DistributedSampler(eval_data)\n",
    "    eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=eval_batch_size)\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    true_labels=[]\n",
    "    pred_labels=[]\n",
    "    logits_history=[]\n",
    "    for input_ids, input_mask, segment_ids, label_ids in tqdm(eval_dataloader):\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        label_ids = label_ids.to(device)\n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss, temp_logits = model(input_ids, segment_ids, input_mask, label_ids)\n",
    "            logits = model(input_ids,segment_ids,input_mask)\n",
    "\n",
    "        logits = torch.squeeze(m(logits)).detach().cpu().numpy()\n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "\n",
    "        outputs = np.asarray([1 if i else 0 for i in (logits.flatten()>=0.5)])\n",
    "        tmp_eval_accuracy=np.sum(outputs == label_ids)\n",
    "\n",
    "        true_labels = true_labels + label_ids.flatten().tolist()\n",
    "        pred_labels = pred_labels + outputs.flatten().tolist()\n",
    "        logits_history = logits_history + logits.flatten().tolist()\n",
    "\n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        nb_eval_examples += input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_examples\n",
    "    df = pd.DataFrame({'logits':logits_history, 'pred_label': pred_labels, 'label':true_labels})\n",
    "\n",
    "    string = 'logits_clinicalbert_'+readmission_mode+'_chunks.csv'\n",
    "    df.to_csv(os.path.join(output_dir1, string))\n",
    "\n",
    "    df_test = pd.read_csv(os.path.join(data_dir, \"test.csv\"))\n",
    "\n",
    "    fpr, tpr, df_out = vote_score(df_test, logits_history, readmission_mode, output_dir1)\n",
    "\n",
    "    string = 'logits_clinicalbert_'+readmission_mode+'_readmissions.csv'\n",
    "    df_out.to_csv(os.path.join(output_dir1,string))\n",
    "\n",
    "    rp80 = vote_pr_curve(df_test, logits_history, readmission_mode, output_dir1)\n",
    "\n",
    "    result = {'eval_loss': eval_loss,\n",
    "              'eval_accuracy': eval_accuracy,                 \n",
    "              'global_step': global_step_check,\n",
    "              'training loss': train_loss/number_training_steps,\n",
    "              'RP80': rp80}\n",
    "\n",
    "    output_eval_file = os.path.join(output_dir1, \"eval_results.txt\")\n",
    "    with open(output_eval_file, \"w\") as writer:\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
